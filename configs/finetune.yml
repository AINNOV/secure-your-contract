base_model: "meta-llama/Llama-2-7b-chat-hf"
hf_token: "../../hf_token.txt"
eval_contract:
  - ../data/evaluation_contract1.txt
  - ../data/evaluation_contract2.txt
eval_GT:
  - ../data/evaluation_GT1.txt
  - ../data/evaluation_GT2.txt
  
dataset:
  train: "JJuny/llama2_SYC_1120_with_testPDF_revisedtemplate_train"
  eval: "JJuny/llama2_SYC_1120_with_testPDF_revisedtemplate_eval"

training:
  output_dir: "../log/SYC_1120_evalmetrics_pdfs_revisedtemplate_training"
  batch_size: 6
  batch_size_eval: 4
  learning_rate: 1e-4
  epochs: 30
  logging_steps: 30
  save_steps: 500
  fp16: true
  save_model_path: "../pretrained/SYC_1120_evalmetrics_pdfs_revisedtemplate"

lora:
  r: 16
  alpha: 32
  dropout: 0.1

